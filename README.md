bot-beta ğŸ¤–
Una interfaz grÃ¡fica simple y efectiva para interactuar con modelos de lenguaje de Ollama usando Streamlit. Su unico objetivo es testear de modo local el llm de OLlama.

ğŸ“‹ Prerequisitos

Python 3.8 o superior
Ollama instalado en tu sistema
Modelo LLaMA 2 (7B) descargado en Ollama

ğŸ”§ InstalaciÃ³n

Clona el repositorio
Instala las dependencias desde requirements.txt
AsegÃºrate de tener Ollama iniciado y el modelo LLaMA 2 descargado

ğŸ’» Uso

Inicia el servidor de Ollama
Ejecuta la aplicaciÃ³n Streamlit
Abre tu navegador en http://localhost:8501

ğŸ“ Estructura del Proyecto
Copyollama-streamlit-bot/
â”œâ”€â”€ app.py              # AplicaciÃ³n principal
â”œâ”€â”€ requirements.txt    # Dependencias del proyecto
â””â”€â”€ README.md          # Este archivo
ğŸ“ Requirements.txt
Copystreamlit>=1.24.0
requests>=2.31.0
ğŸ¤ Contribuciones
Las contribuciones son bienvenidas. Por favor, abre un issue primero para discutir quÃ© te gustarÃ­a cambiar.
âš ï¸ SoluciÃ³n de Problemas
Si encuentras el error "404 Client Error: Not Found", verifica:

Que Ollama estÃ¡ corriendo
Que el modelo estÃ¡ instalado
Que el servidor estÃ¡ accesible en localhost:11434

ğŸ“„ Licencia
Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo LICENSE.md para mÃ¡s detalles.
ğŸ‘¤ charly aguiar


GitHub: Charlesagui


â­ï¸ Muestra tu Apoyo
Si este proyecto te ha sido Ãºtil, considera darle una estrella en GitHub.
ğŸ“ Notas

Esta aplicaciÃ³n estÃ¡ diseÃ±ada para uso local y educativo
El rendimiento dependerÃ¡ de tu hardware
Se recomienda tener al menos 16GB de RAM para un funcionamiento Ã³ptimo